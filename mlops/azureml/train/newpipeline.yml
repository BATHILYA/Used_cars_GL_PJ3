$schema: https://azuremlschemas.azureedge.net/latest/pipelineJob.schema.json
type: pipeline
display_name: random_forest_training_pipeline  # Provide the display name for the pipeline
experiment_name: used-cars-price-regressor-training  # Provide the experiment name
description: Training Pipeline to predict used cars prices using random forest regressor  # Provide the description for the pipeline

inputs:
  raw_data:
    type: uri_file
    path: azureml:used-cars-price-data@latest
  
  hf_token: ""
  hf_model_repo_id: "AbdramaneB/used-cars-price-model"
  hf_space_repo_id: "AbdramaneB/used-cars-price-prediction"
  model_filename: "best_price_model_v2.joblib"
  revision_note: "Model published from AzureML pipeline"


outputs:
  train_data:
    type: uri_folder  # Specify the type for train_data output
  test_data:
    type: uri_folder  # Specify the type for test_data output
  model_info_output_path:
    type: uri_file  # Specify the type for model_info_output_path output

settings:
  default_datastore: azureml:workspaceblobstore
  default_compute: azureml:pj3-ds11-cluster
  continue_on_step_failure: false

jobs:
  prep_data:
    compute: azureml:pj3-ds11-cluster
    name: prep_data  # Provide the job name
    display_name: prep-data  # Provide the display name for the job
    code: ../../../data-science/src
    command: >-
      python prep.py  
      --raw_data ${{inputs.raw_data}} 
      --train_data ${{outputs.train_data}}
      --test_data ${{outputs.test_data}} 
    environment: azureml:used-cars-train-env@latest
    inputs:
      raw_data: ${{parent.inputs.raw_data}}
    outputs:
      train_data: ${{parent.outputs.train_data}}
      test_data: ${{parent.outputs.test_data}}

  sweep_step:
    compute: azureml:pj3-ds11-cluster
    name: sweep_job
    display_name: sweep-job  # Hint: Provide the display name for the job
    type: sweep
    inputs:
      train_data: ${{parent.jobs.prep_data.outputs.train_data}}
      test_data: ${{parent.jobs.prep_data.outputs.test_data}}
    outputs:
      model_output:
        type: mlflow_model
    sampling_algorithm: random  # Specify the sampling algorithm
    trial: ./train.yml  # Refers to a separate command component
    search_space:
      n_estimators:
        type: choice
        values: [10, 20, 30, 50]
      max_depth:
        type: choice  # Specify the type for max_depth
        values: [1,3,5,10]  # Provide the values for max_depth
    objective:
      goal: maximize
      primary_metric: R_squared
    limits:
      max_total_trials: 5
      max_concurrent_trials: 10
      timeout: 7200


  register_model:
    compute: azureml:pj3-ds11-cluster
    name: register_model  # Provide the job name
    display_name: register-model  # Provide the display name for the job
    code: ../../../data-science/src
    command: >-
      python register.py 
      --model_name ${{inputs.model_name}} 
      --model_path ${{inputs.model_path}} 
      --model_info_output_path ${{outputs.model_info_output_path}}
    environment: azureml:used-cars-train-env@latest
    inputs:
      model_name: "used_cars_price_prediction_model"
      model_path: ${{parent.jobs.sweep_step.outputs.model_output}}
    outputs:
      model_info_output_path: ${{parent.outputs.model_info_output_path}}

# ---------------- publish best model to HF Model repo ----------------
  publish_model_to_hf_model:
    compute: azureml:pj3-ds11-cluster
    name: publish_model_to_hf_model
    display_name: Publish best model to HF Model repo
    code: ../../../data-science/src
    environment: azureml:hf-push-env@latest
    environment_variables:
      HF_TOKEN: ${{parent.inputs.hf_token}}
    inputs:
      model_dir: ${{parent.jobs.sweep_step.outputs.model_output}}
      model_repo_id: ${{parent.inputs.hf_model_repo_id}}
      model_filename: ${{parent.inputs.model_filename}}
      revision_note: ${{parent.inputs.revision_note}}
    outputs:
      done:
        type: uri_file
    command: >-
      python export_and_push_model_to_hf_model_repo.py
      --model_dir ${{inputs.model_dir}}
      --model_repo_id ${{inputs.model_repo_id}}
      --model_filename ${{inputs.model_filename}}
      --revision_note "${{inputs.revision_note}}"
      --done_out ${{outputs.done}}

  # ---------------- push Space files to HF Space (runs AFTER publish) ----------------
  push_space_files_to_hf:
    depends_on: publish_model_to_hf_model
    compute: azureml:pj3-ds11-cluster
    name: push_space_files_to_hf
    display_name: Push Space files to Hugging Face
    code: ../../../
    environment: azureml:hf-push-env@latest
    environment_variables:
      HF_TOKEN: ${{parent.inputs.hf_token}}
    inputs:
      space_repo_id: ${{parent.inputs.hf_space_repo_id}}
    command: >-
      python data-science/src/push_space_files_to_hf.py
      --deployment_dir HGF_deployment
      --space_repo_id ${{inputs.space_repo_id}}

